ğŸ¤– BotTrainer â€“ LLM-Based NLU Model Trainer & Evaluator

BotTrainer is an LLM-powered Natural Language Understanding (NLU) system designed for chatbot applications.
Instead of training traditional machine learning models, this project uses prompt engineering and few-shot learning with modern Large Language Models (LLMs) to perform intent classification and evaluate performance using standard ML metrics.

ğŸš€ Key Features

ğŸ” Intent Classification using LLMs (LLaMA 3 via Groq â€“ free & fast)

ğŸ§  Prompt Engineering & Few-Shot Learning

ğŸ“Š Model Evaluation with Accuracy, Precision, Recall, F1-score

ğŸ“‰ Confusion Matrix Visualization

ğŸ§ª Structured JSON Output Enforcement

ğŸ–¥ï¸ Interactive Multi-Page Streamlit UI

ğŸ§© Modular, ML-style Project Architecture

ğŸ“ Centralized Logging & Custom Exception Handling

ğŸ› ï¸ Tech Stack

Python 3.10+

Groq API (LLaMA 3.1 models)

Streamlit (UI)

Scikit-learn (evaluation metrics)

PyYAML (config management)

Matplotlib (visualization)

ğŸ“‚ Project Structure
BotTrainer_nlu/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_Test_Intent_Classification.py
â”‚       â””â”€â”€ 2_Evaluate_Model_Performance.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ intents.json
â”‚   â””â”€â”€ eval_data.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”‚   â”œâ”€â”€ llm_inference.py
â”‚   â”‚   â””â”€â”€ intent_classifier.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ inference_pipeline.py
â”‚   â”‚   â””â”€â”€ evaluation_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”œâ”€â”€ logging_system.py
â”‚   â””â”€â”€ exceptions.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md

ğŸ§  How This Project Works
ğŸ”¹ Important Concept

The LLM is NOT trained in this project.

Instead:

A pre-trained LLM is used

The task is defined using prompt engineering

The system is evaluated like a traditional ML model

ğŸ§© Components Explained
1ï¸âƒ£ intents.json

Defines the intent space

Provides few-shot examples

Used to ground the LLM

2ï¸âƒ£ Prompt Engineering

Intent definitions + examples are injected into prompts

Enforces strict JSON output

Replaces feature engineering and model training

3ï¸âƒ£ Inference Pipeline

Builds prompt

Calls LLM

Parses structured response

Returns predicted intent + confidence

4ï¸âƒ£ Evaluation Pipeline

Uses eval_data.json as ground truth

Compares predicted intent vs actual intent

Computes:

Accuracy

Precision

Recall

F1-score

Generates confusion matrix

ğŸ“Š Evaluation Strategy

Closed-set intent classification

Same intent labels as intents.json

Different (unseen) user utterances in eval_data.json

Metrics are meaningful and ML-correct

Intent labels in eval_data.json are never shown to the LLM â€” they are used only for scoring.

ğŸ–¥ï¸ Streamlit Application

The UI is implemented as a multi-page Streamlit app:

ğŸ§  Page 1 â€“ Test Intent Classification

Enter any sentence

View predicted intent and confidence

Real-time LLM inference

ğŸ“Š Page 2 â€“ Evaluate Model Performance

Run full evaluation on labeled dataset

View metrics

Visualize confusion matrix

Run the app:

streamlit run app/streamlit_app.py

âš™ï¸ Configuration
ğŸ“„ config/config.yaml
llm:
  provider: groq
  model: llama-3.1-8b-instant
  temperature: 0.2
  max_tokens: 300

paths:
  intents_path: data/intents.json
  eval_path: data/eval_data.json

evaluation:
  confidence_threshold: 0.6

ğŸ” Environment Setup

1ï¸âƒ£ Create virtual environment:

python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate


2ï¸âƒ£ Install dependencies:

pip install -r requirements.txt


3ï¸âƒ£ Create .env file:

GROQ_API_KEY=your_api_key_here

ğŸ“ Logging & Error Handling

Centralized logging stored in artifacts/logs/

Timestamped log files for each run

Custom NLUException for clean error propagation

ğŸ¯ Learning Outcomes

Through this project, you learn:

LLM-based NLU system design

Prompt engineering as a replacement for ML training

Intent classification pipelines

ML-style evaluation of LLM systems

Streamlit app development

Logging, configuration, and error handling

Clean, scalable project structuring

ğŸ“Œ Future Enhancements

Entity extraction & slot filling

Entity-level evaluation metrics

Unknown intent (OOD) detection

Error analysis dashboard

Docker deployment
